
### ferry

ferry工单系统，最重要的其实是工单流程的逻辑，还有工单任务的执行调度，这部分交给了machinery库。

- 路由分组注册
- casbin权限管理
- JWT

其他见ferry.md

### gee

### geecache

### geeorm

geeorm用到了database/sql，将对数据库的操作封装起来，实际是提取变量组成sql语句进行执行，首先就是包装了sql.DB的执行和查询等函数

然后实现了数据库的表与go语言结构体之间的转换，进一步封装对表的操作

接着一些复杂的语句需要先分解成多个从句，每个从句进行组装后才能执行，所以引入clause包

hook的实现是和表相关的，作为表的方法，通过反射拿到对应表的方法，在操作中调用

### geerpc

### strings.Builder

其实原理是将string转换成[]byte，进行拼接，最后再以string输出，string如果直接用+，又不string不可变会导致重复分配内存

### atomic

原子操作由底层硬件支持，而锁则由操作系统的调度器实现。**锁应当用来保护一段逻辑，对于一个变量更新的保护，原子操作通常会更有效率**，并且更能利用计算机多核的优势，如果要更新的是一个复合对象，则应当使用`atomic.Value`封装好的实现。

底层实现：Mutex由**操作系统的调度器**实现，而atomic包中的原子操作则由**底层硬件指令直接提供支持**，这些指令在执行的过程中是不允许中断的，因此原子操作可以在lock-free的情况下保证并发安全，并且它的性能也能做到随CPU个数的增多而线性扩展。

其实Mutex的底层实现也是依赖原子操作中的CAS实现的，原子操作的atomic包相当于是sync包里的那些同步原语的实现依赖

Go语言通过内置包sync/atomic提供了对原子操作的支持，其提供的原子操作有以下几大类：
- 增减，操作的方法名方式为AddXXXType，保证对操作数进行原子的增减，支持的类型为int32、int64、uint32、uint64、uintptr，使用时以实际类型替换前面我说的XXXType就是对应的操作方法。
- 载入，保证了读取到操作数前没有其他任务对它进行变更，操作方法的命名方式为LoadXXXType，支持的类型除了基础类型外还支持Pointer，也就是支持载入任何类型的指针。
- 存储，有载入了就必然有存储操作，这类操作的方法名以Store开头，支持的类型跟载入操作支持的那些一样。
- 比较并交换，也就是CAS （Compare And Swap），像Go的很多并发原语实现就是依赖的CAS操作，同样是支持上面列的那些类型。
- 交换，这个简单粗暴一些，不比较直接交换，这个操作很少会用。

### sync.Cond

```go
var done = false

func read(name string, c *sync.Cond) {
	c.L.Lock()
	for !done {
		c.Wait()
	}
	fmt.Println(name, "starts reading")
	c.L.Unlock()
}

func write(name string, c *sync.Cond) {
	fmt.Println(name, "starts writing")
	time.Sleep(time.Second)
	done = true
	fmt.Println(name, "wakes all")
	c.Broadcast()
}

func main() {
	cond := sync.NewCond(&sync.Mutex{})

	go read("reader1", cond)
	go read("reader2", cond)
	go read("reader3", cond)
	write("writer", cond)

	time.Sleep(time.Second * 3)
}
```

sync.Cond 不能被复制的原因，并不是因为其内部嵌套了 Locker。NewCond 时传入的 Mutex/RWMutex 指针，对于 Mutex 指针复制是没有问题的。

主要原因是 sync.Cond 内部是维护着一个 Goroutine 通知队列 notifyList。如果这个队列被复制的话，那么在并发场景下导致不同 Goroutine 之间操作的 notifyList.wait、notifyList.notify 并不是同一个，这会导致出现有些 Goroutine 会一直阻塞。

实际上 sync.Cond 与 Channel 是有区别的，channel 定位于通信，用于一发一收的场景，sync.Cond 定位于同步，用于一发多收的场景。虽然 channel 可以通过 close 操作来达到一发多收的效果，但是 closed 的 channel 已无法继续使用，而 sync.Cond 依旧可以继续使用。这可能就是“全能”与“专精”的区别。

### 值拷贝

go中值类型只需要赋值操作就可以进行复制，引用类型会复制指针，所以复制一个结构体就是:=就行

### 切片内存陷阱

如果一直做切片操作，可能导致实际用到的内存很少，但是底层数组大量空间无法释放的问题，可以通过copy来解决，这样会创建新的底层数组，原来的被GC

### 内存对齐

[ref](https://geektutu.com/post/hpg-struct-alignment.html)

CPU 始终以字长访问内存，如果不进行内存对齐，很可能增加 CPU 访问内存的次数

在对内存特别敏感的结构体的设计上，我们可以通过调整字段的顺序，减少内存的占用

### sync.Pool

[ref](https://www.cnblogs.com/qcrao-2018/p/12736031.html)

理解：sync.Pool的目的是在多个goroutine每个都需要一个对象，但是如果每个goroutine都创建对象就浪费的情况，解决这个问题，使得goroutine直接可以从Pool里拿到对象就行，如果没有就会自动创建。

需要注意的点：Get之后Pool里的对象就没了，需要再Put进去，且最好将对象清空之后放进去，因为这样其他goroutine才能安全使用，这里的对象就类似于一组方法集

对于很多需要重复分配、回收内存的地⽅，sync.Pool 是⼀个很好的选择。频繁地分配、回收内存会给 GC 带来⼀定的负担，严重的时候会引起 CPU 的⽑刺，⽽ sync.Pool 可以将暂时不⽤的对象缓存起来，待下次需要的时候直接使⽤，不⽤再次经过内存分配，复⽤对象的内存，减轻 GC 的压⼒，提升系统的性能。

相当于一个临时存储，sync.Pool 的大小是可伸缩的，高负载时会动态扩容，存放在池中的对象如果不活跃了会被自动清理。

### 大端 小端

[ref](https://www.ruanyifeng.com/blog/2022/06/endianness-analysis.html)

大端序的最高位在左边，最低位在右边，符合阅读习惯。所以，对于这些国家的人来说，从左到右的大端序的可读性更好。

但是现实中，从右到左的小端序虽然可读性差，但应用更广泛，x86 和 ARM 这两种 CPU 架构都采用小端序，这是为什么？

或者换一种问法，两种不同的字节序为什么会并存，统一规定只使用一种，难道不是更方便吗？

原因是它们有各自的适用场景，某些场景大端序有优势，另一些场景小端序有优势，下面就逐一分析。

**如果需要逐位运算，或者需要到从个位数开始运算，都是小端序占优势。反之，如果运算只涉及到高位，或者数据的可读性比较重要，则是大端序占优势。**

```go
// 判断是否大端序
var data int32 = 1
pointer := unsafe.Pointer(&data)
bp := (*byte)(pointer)
if *bp == 1 {
	fmt.Println(true)
}
	```

### 内存管理

总结起来关于Go内存分配管理的策略有如下几点：

- Go在程序启动时，会向操作系统申请一大块内存，由`mheap`结构全局管理。
- Go内存管理的基本单元是`mspan`，每种`mspan`可以分配特定大小的object。
- `mcache`, `mcentral`, `mheap`是Go内存管理的三大组件，`mcache`管理线程在本地缓存的`mspan`；`mcentral`管理全局的`mspan`供所有线程使用；`mheap`管理Go的所有动态分配内存。
- 一般小对象通过`mspan`分配内存；大对象则直接由`mheap`分配内存。

分段栈 -> 连续栈
栈扩容、栈缩容

#### 堆内存管理

`go tool compile -m main.go`打印优化决定，可以看出是否逃逸到堆
借助命令`go tool compile -S main.go`，可以显示该程序的汇编代码，也可以明确地向我们展示内存的分配

**小于32KB内存块的分配策略**

当程序里发生了32kb以下的小块内存申请时，Go会从一个叫做的mcache的本地缓存给程序分配内存。这个本地缓存mcache持有一系列的大小为32kb的内存块，这样的一个内存块里叫做`mspan`，它是要给程序分配内存时的分配单元。

在Go的调度器模型里，每个线程M会绑定给一个处理器P，在单一粒度的时间里只能做多处理运行一个goroutine，每个P都会绑定一个上面说的本地缓存`mcache`。当需要进行内存分配时，当前运行的goroutine会从mcache中查找可用的mspan。从本地mcache里分配内存时不需要加锁，这种分配策略效率更高。

mcache持有的这一系列的mspan并不都是统一大小的，而是按照大小，从8字节到32KB分了大概70类的msapn。

现在，我们可能会好奇，如果分配内存时mcachce里没有空闲的32字节的mspan了该怎么办？Go里还为每种类别的mspan维护着一个`mcentral`。

mcentral的作用是为所有mcache提供切分好的mspan资源。**每个central会持有一种特定大小的全局mspan列表**，包括已分配出去的和未分配出去的。每个mcentral对应一种mspan，当工作线程的mcache中没有合适（也就是特定大小的）的mspan时就会从mcentral 去获取。mcentral被所有的工作线程共同享有，存在多个goroutine竞争的情况，因此从mcentral获取资源时需要加锁。

mcentral里维护着两个双向链表，nonempty表示链表里还有空闲的mspan待分配。empty表示这条链表里的mspan都被分配了object。

简单说下mcache从mcentral获取和归还mspan的流程：

- 获取 加锁；从nonempty链表找到一个可用的mspan；并将其从nonempty链表删除；将取出的mspan加入到empty链表；将mspan返回给工作线程；解锁。
- 归还 加锁；将mspan从empty链表删除；将mspan加入到nonempty链表；解锁。

当mcentral没有空闲的mspan时，会向`mheap`申请。而mheap没有资源时，会向操作系统申请新内存。mheap主要用于大对象的内存分配，以及管理未切割的mspan，用于给mcentral切割成小对象。

同时我们也看到，mheap中含有所有规格的mcentral，所以，当一个mcache从mcentral申请mspan时，只需要在独立的mcentral中使用锁，并不会影响申请其他规格的mspan。

上面说了每种尺寸的mspan都有一个全局的列表存放在mcentral里供所有线程使用，所有mcentral的集合则是存放于mheap中的。mheap里的`arena` 区域是真正的堆区，运行时会将 8KB 看做一页，这些内存页中存储了所有在堆上初始化的对象。运行时使用二维的 runtime.heapArena 数组管理所有的内存，每个 runtime.heapArena 都会管理 **64MB** 的内存。

**大于32KB内存块的分配策略**

Go没法使用工作线程的本地缓存mcache和全局中心缓存mcentral上管理超过32KB的内存分配，所以对于那些超过32KB的内存申请，会直接从堆上(mheap)上分配对应的数量的内存页（**每页大小是8KB**）给程序。

#### 栈内存管理

在Go应用程序运行时，每个goroutine都维护着一个自己的栈区，这个栈区只能自己使用不能被其他goroutine使用。栈区的初始大小是2KB（比x86_64架构下线程的默认栈2M要小很多），在goroutine运行的时候栈区会按照需要增长和收缩，占用的内存最大限制的默认值在64位系统上是1GB。

分段栈：

Go 1.3 版本前使用的栈结构是分段栈，随着goroutine 调用的函数层级的深入或者局部变量需要的越来越多时，运行时会调用 runtime.morestack 和 runtime.newstack创建一个新的栈空间，这些栈空间是不连续的，但是当前 goroutine 的多个栈空间会以双向链表的形式串联起来，运行时会通过指针找到连续的栈片段

分段栈虽然能够按需为当前 goroutine 分配内存并且及时减少内存的占用，但是它也存在一个比较大的问题：
- 如果当前 goroutine 的栈几乎充满，那么任意的函数调用都会触发栈的扩容，当函数返回后又会触发栈的收缩，如果在一个循环中调用函数，栈的分配和释放就会造成巨大的额外开销，这被称为热分裂问题（Hot split）。

连续栈：

连续栈可以解决分段栈中存在的两个问题，其核心原理就是每当程序的栈空间不足时，初始化一片比旧栈大一倍的新栈并将原栈中的所有值都迁移到新的栈中，新的局部变量或者函数调用就有了充足的内存空间。使用连续栈机制时，栈空间不足导致的扩容会经历以下几个步骤：

- 调用用runtime.newstack在内存空间中分配更大的栈内存空间；
- 使用runtime.copystack将旧栈中的所有内容复制到新的栈中；
- 将指向旧栈对应变量的指针重新指向新栈；
- 调用runtime.stackfree销毁并回收旧栈的内存空间；

请注意**栈扩容后同一个变量的内存地址会发生变化**

每个goroutine都维护着自己的栈区，栈结构是连续栈，是一块连续的内存，在goroutine的类型定义的源码里我们可以找到标记着栈区边界的stack信息，stack里记录着栈区边界的高位内存地址和低位内存地址

栈内容的申请也是和堆一样，先去当前线程的对应尺寸的mcache里去申请，不够的时候mcache会从全局的mcental里取内存等等

栈扩容：

编译器会为函数调用插入运行时检查runtime.morestack，它会在几乎所有的函数调用之前检查当前goroutine 的栈内存是否充足，如果当前栈需要扩容，会调用runtime.newstack 创建新的栈

旧栈的大小是通过我们上面说的保存在goroutine中的stack信息里记录的栈区内存边界计算出来的，然后用旧栈两倍的大小创建新栈，创建前会检查是新栈的大小是否超过了单个栈的内存上限。

栈缩容：

在goroutine运行的过程中，如果栈区的空间使用率不超过1/4，那么在垃圾回收的时候使用runtime.shrinkstack进行栈缩容，当然进行缩容前会执行一堆前置检查，都通过了才会进行缩容

如果要触发栈的缩容，新栈的大小会是原始栈的一半，不过如果新栈的大小低于程序的最低限制 2KB，那么缩容的过程就会停止。缩容也会调用扩容时使用的 runtime.copystack 函数开辟新的栈空间，将旧栈的数据拷贝到新栈以及调整原来指针的指向。

### GC

可以配合undergo.md#垃圾回收-garbage-collection

[ref](https://www.yuque.com/aceld/golang/zhzanb)

[非常容易理解的博文，建议只看这个](https://www.cnblogs.com/cxy2020/p/16321884.html)

标记清除算法明了，过程鲜明干脆，但是也有非常严重的问题。

- STW，stop the world；让程序暂停，程序出现卡顿 (重要问题)；
- 标记需要扫描整个heap；
- 清除数据会产生heap碎片。

**Go V1.3** 做了简单的优化,将STW的步骤提前, 减少STW暂停的时间范围

**将STW的步骤提前了一步**，因为在Sweep清除的时候，可以不需要STW停止，因为这些对象已经是不可达对象了，不会出现回收写冲突等问题。

**没有STW的三色标记法会出现错误**

**Go V1.5**

可以看出，有两种情况，在三色标记法中，是不希望被发生的。

- 条件1: 一个白色对象被黑色对象引用(白色被挂在黑色下)
- 条件2: 灰色对象与它之间的可达关系的白色对象遭到破坏(灰色同时丢了该白色)
如果当以上两个条件同时满足时，就会出现对象丢失现象!

插入屏障与删除屏障对栈上对象不会生效

- 插入写屏障：黑色节点新引用到白色节点前，把白色节点变为灰色
- 删除写屏障：灰色节点删除到白色节点的引用时，把白色节点变成灰色节点

插入写屏障不足：结束时需要STW来重新扫描栈
删除写屏障不足：回收精度低，需要下一次回收才能回收掉被删除引用的白色垃圾对象

>疑问：栈按理说不应该进行GC，为什么会扫描栈空间？如果栈指针引用了堆上的对象，那不还是按照堆对象进行gc吗？和栈有什么关系？还是说栈指针引用了堆对象后，需要对该栈帧进行扫描，但是不使用屏障

上述猜想是正确的，这里的栈对象本身还是在堆上，只是被栈上指针引用，GO的gc会扫描栈来找到栈指针指向的堆对象，来确定引用关系

**Go V1.8**

插入写屏障和删除写屏障的短板：

- 插入写屏障：结束时需要STW来重新扫描栈，标记栈上引用的白色对象的存活； 
- 删除写屏障：回收精度低，GC开始时STW扫描堆栈来记录初始快照，这个过程会保护开始时刻的所有存活对象。 

Go V1.8版本引入了混合写屏障机制（hybrid write barrier），避免了对栈re-scan的过程，极大的减少了STW的时间。结合了两者的优点。

1、GC刚开始的时候，会将栈上的可达对象全部标记为黑色(之后不再进行第二次重复扫描，无需STW)，

2、GC期间，任何在栈上创建的新对象，均为黑色。

3、对该对象触发，被删除“引用”的白色对象标记为灰色。

4、对该对象触发，被添加“引用”的白色对象标记为灰色。

满足: 变形的弱三色不变式.

上面两点只有一个目的，将栈上的可达对象全部标黑，最后无需对栈进行STW，就可以保证栈上的对象不会丢失。有人说，一直是黑色的对象，那么不就永远清除不掉了么，这里强调一下，标记为黑色的是可达对象，不可达的对象一直会是白色，直到最后被回收。

1.8版本还有STW吗？

1. STW就是为了开启写屏障，这也是GC开始的第一步，开启写屏障之后就是并发标记，标记结束后，再来一个STW，关闭写屏障。最后就是清理工作。
2. 混合写屏障是去除整体的STW 的一个改进，转而并发一个一个栈处理的方式(每个栈单独暂停)，从而消除了整机 STW 的影响，带来了吞吐的提升。

GC是一轮一轮触发的，不是整个运行过程只有一次

#### GC触发

1. 程序内存不足
2. 程序内存使用到达阈值
3. sysmon监控到一段时间没有GC
4. 手动触发runtime.GC

### GMP

可以配合undergo.md#gmp-gpm

[ref](https://www.yuque.com/aceld/golang/zhzanb)

调度器策略:

1）work stealing机制

当本线程无可运行的G时，先尝试全局队列，再尝试从其他线程绑定的P偷取G，而不是销毁线程。

2）hand off机制

当本线程因为G进行**系统调用阻塞**时，线程释放绑定的P，把P转移给其他空闲的线程执行。

场景:

创建goroutine时，可能创建在本地队列中，满足局部性，如果满了，会分割队列，拿出队列前面的一半打乱放入全局队列

>局部性，同一个核有l1,l2 cache，分配到同一个线程容易命中，提高执行效率

也可能会唤醒其他M，分配到那个M

自旋线程就是M对应的P本地队列没有要执行的协程，但是该线程是运行状态

偷取其他P的G时，也是分割队列，取后一半

#### m0 g0

m0是第一个线程，在全局变量runtime.m0中，不分配在堆上

g0是每个m的绑定的唯一goroutine，负责goroutine调度

### 几种并发模型

**传统的并发模型**

多线程编程，采用**共享内存**的方式，加锁解锁资源

**基于消息的并发模型**

Actor: 
- 消息是直接发送到对方的，没有中介
- 消息的收发是异步的，类似邮箱

CSP:
- 消息是发送到channel的，不区分发送者与接收者对象是谁
- 消息的收发是同步的，或者有限异步

它们都是描述独立的流程通过消息传递进行通信 主要的区别在于：在CSP消息交换是同步的(即两个流程的执行"接触点"的，在此他们交换消息)，而Actor模型是完全解耦的，可以在任意的时间将消息发送给任何未经证实的接受者。

由于Actor享有更大的相互独立,因为他可以根据自己的状态选择处理哪个传入消息。自主性更大些。

在Go语言中为了不堵塞流程，程序员必须检查不同的传入消息，以便预见确保正确的顺序。CSP好处是Channel不需要缓冲消息，而Actor理论上需要一个无限大小的邮箱作为消息缓冲

### 超时退出协程相关问题

[ref](https://geektutu.com/post/hpg-timeout-goroutine.html)

```go
func doBadThing(done chan bool) {
	time.Sleep(time.Second)
	done <- true
}

func timeout(f func(chan bool)) error {
	done := make(chan bool) //问题是doBadThing协程会被阻塞，如果超时退出的话
	go f(done)
	select {
	case <-done:
		fmt.Println("done")
		return nil
	case <-time.After(time.Millisecond):
		return fmt.Errorf("timeout")
	}
}
```

解决方案是1.创建有缓存的channel 2.协程使用select

注意点：channel的发送和接收都得注意，如果没有用select，就得对应好发送和接收，否则协程无法退出


### 通道 channel

[ref](https://gfw.go101.org/article/channel.html)

#### 通道关闭原则

[ref](https://gfw.go101.org/article/channel-closing.html)

一个常用的使用Go通道的原则是不要在数据接收方或者在有多个发送者的情况下关闭通道。 换句话说，我们**只应该让一个通道唯一的发送者关闭此通道**。

为什么不能接受方关闭通道？

因为接收方关闭通道，发送方不能往关闭的channel发送数据，会panic，而又没有不影响channel状态探测到channel是否关闭的手段，所以只能发送方关闭，且只能唯一的发送方关闭。

情形一：M个接收者和一个发送者。发送者通过关闭用来传输数据的通道来传递发送结束信号

这是最简单的一种情形。当发送者欲结束发送，让它关闭用来传输数据的通道即可。

情形二：一个接收者和N个发送者，此唯一接收者通过关闭一个额外的信号通道来通知发送者不要再发送数据了

此情形比上一种情形复杂一些。我们不能让接收者关闭用来传输数据的通道来停止数据传输，因为这样做违反了通道关闭原则。 但是我们可以让接收者关闭一个额外的信号通道来通知发送者不要再发送数据了。

这个方法就是多加一个通道，这个通道的语境里，就是一发多收，所以可以

情形三：M个接收者和N个发送者。它们中的任何协程都可以让一个中间调解协程帮忙发出停止数据传送的信号

这是最复杂的一种情形。我们不能让接收者和发送者中的任何一个关闭用来传输数据的通道，我们也不能让多个接收者之一关闭一个额外的信号通道。 这两种做法都违反了通道关闭原则。 然而，我们可以引入一个中间调解者角色并让其关闭额外的信号通道来通知所有的接收者和发送者结束工作。

#### 关于通道和协程的垃圾回收

注意，一个通道被其发送数据协程队列和接收数据协程队列中的所有协程引用着。因此，如果一个通道的这两个队列只要有一个不为空，则此通道肯定不会被垃圾回收。

另一方面，如果一个协程处于一个通道的某个协程队列之中，则此协程也肯定不会被垃圾回收，即使此通道仅被此协程所引用。事实上，一个协程只有在退出后才能被垃圾回收。
